{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "rNegjqwoDnJw"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "$$HAMI: \\ Hippocampal-Augmented \\ Memory \\ Integration$$"
      ],
      "metadata": {
        "id": "vy0NT8jAO1xu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "jZEBD-EhGMKu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeo-WZurF-DN",
        "outputId": "72761529-9624-4138-f45c-d3cfd72fa20f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import gymnasium as gym\n",
        "from gym import spaces\n",
        "from collections import deque\n",
        "from collections import namedtuple\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from collections import namedtuple, deque\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import sys"
      ],
      "metadata": {
        "id": "UIbEm7ROGDjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtdEN1gRGFG3",
        "outputId": "8302f4f4-df1a-4731-ea48-348aec9dbbf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xIiSaiqiGGkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tA22KrfYlWCy"
      },
      "source": [
        "# Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dG2D6ENmhR1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8375b932-9f79-4904-9ebd-870b05a08831"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 44.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 2.37MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 13.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.69MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Define the transformation to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define the four distinctive colors (R, G, B values)\n",
        "colors = {\n",
        "    \"blue\": [25, 50, 100],\n",
        "    \"red\": [225, 75, 25],\n",
        "    \"green\": [50, 100, 75],\n",
        "    \"yellow\": [175, 150, 50]\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmduBzGJhUU7"
      },
      "outputs": [],
      "source": [
        "def colorize_mnist(images, color):\n",
        "    colorized_images = []\n",
        "    for img in images:\n",
        "\n",
        "        img_colored = torch.zeros((3, 28, 28))   # Create an RGB image with black background\n",
        "\n",
        "        # Change the background color\n",
        "        for i in range(3):\n",
        "            img_colored[i, :, :] = 1- ((1 - img)* (1-(color[i]/255)))\n",
        "        colorized_images.append(img_colored)\n",
        "\n",
        "    return colorized_images\n",
        "\n",
        "\n",
        "# Organize the data by digit categories\n",
        "def organize_by_digit_category(data, labels):\n",
        "    organized_data = {i: [] for i in range(10)}\n",
        "    for img, label in zip(data, labels):\n",
        "        organized_data[int(label)].append(img)\n",
        "    return organized_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nruhp6Y-hd6g"
      },
      "outputs": [],
      "source": [
        "# Colorize the MNIST dataset\n",
        "colored_mnist = {}\n",
        "for color_name, color_value in colors.items():\n",
        "    colored_mnist[color_name] = {\n",
        "        \"train\": colorize_mnist((mnist_train.data/255), color_value),\n",
        "        \"test\": colorize_mnist((mnist_test.data/255), color_value)\n",
        "    }\n",
        "\n",
        "# Organize the data by digit categories\n",
        "CMNIST = {}\n",
        "for color_name in colors.keys():\n",
        "    CMNIST[color_name] = {\n",
        "        \"train\": organize_by_digit_category(colored_mnist[color_name][\"train\"], mnist_train.targets),\n",
        "        \"test\": organize_by_digit_category(colored_mnist[color_name][\"test\"], mnist_test.targets)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f2tPN8bAGKDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "mYfmc42NIiod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def moving_average(data, window_size):\n",
        "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')"
      ],
      "metadata": {
        "id": "79UZwHhDIh0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WXkEMhZB1wya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLCr2a1v9HvS"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYQqtJqlEZvI"
      },
      "outputs": [],
      "source": [
        "random.seed(369)\n",
        "class SequenceEnvironment(gym.Env):\n",
        "    def __init__(self, data, seq_length=3, out_of_seq_prob=0.4, mode='train'):\n",
        "        super(SequenceEnvironment, self).__init__()\n",
        "        self.mode = mode\n",
        "        self.data = data\n",
        "        self.seq_length = seq_length\n",
        "        self.out_of_seq_prob = out_of_seq_prob\n",
        "        self.colors = ['blue', 'red', 'green', 'yellow']\n",
        "\n",
        "        # Action space: Predict \"In Sequence\" or \"Out of Sequence\"\n",
        "        self.action_space = spaces.Discrete(2)\n",
        "\n",
        "        # Observation space: The current image\n",
        "        self.observation_space = spaces.Box(low=0, high=1, shape=(3, 28, 28), dtype=np.float32)\n",
        "\n",
        "        self.log = {\n",
        "            'sequence': [],\n",
        "            'actions': [],\n",
        "            'rewards': []\n",
        "        }\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "\n",
        "        self.color = random.choices(self.colors,[8,8,3,3])[0]\n",
        "        self.current_sequence = self._generate_sequence(self.color)\n",
        "        self.current_index = 0\n",
        "        self.done = False\n",
        "        self.log = {\n",
        "            'sequence': self.current_sequence,\n",
        "            'actions': [],\n",
        "            'rewards': []\n",
        "        }\n",
        "        return self.current_sequence[self.current_index]\n",
        "\n",
        "    def step(self, action):\n",
        "        reward = 0\n",
        "\n",
        "        self.correct_action = self._check_correct_action()\n",
        "\n",
        "        if action == self.correct_action:\n",
        "            reward = 0.5 * (self.current_index+1)\n",
        "            self.current_index += 1\n",
        "            if self.current_index >= self.seq_length:\n",
        "                self.done = True\n",
        "        else:\n",
        "            reward = -1\n",
        "            self.done = True\n",
        "\n",
        "        next_state = self.current_sequence[self.current_index] if not self.done else None\n",
        "\n",
        "\n",
        "\n",
        "        # Log the action and reward\n",
        "        self.log['actions'].append(action)\n",
        "        self.log['rewards'].append(reward)\n",
        "\n",
        "\n",
        "        return next_state, reward, self.done, {}\n",
        "\n",
        "    def _generate_sequence(self, color):\n",
        "        if color == 'blue':\n",
        "            start = random.randint(0, 7)\n",
        "            sequence = [start, start + 1, start + 2]\n",
        "        elif color == 'red':\n",
        "            start = random.randint(2, 9)\n",
        "            sequence = [start, start - 1, start - 2]\n",
        "        elif color == 'green':\n",
        "            start = random.choice([0, 2, 4])\n",
        "            sequence = [start, start + 2, start + 4]\n",
        "        elif color == 'yellow':\n",
        "            start = random.choice([1, 3, 5])\n",
        "            sequence = [start, start + 2, start + 4]\n",
        "        self.correct_seq = sequence\n",
        "\n",
        "        images = []\n",
        "        self.observed_seq = []\n",
        "        for i, num in enumerate(sequence):\n",
        "            if i > 0 and random.random() < self.out_of_seq_prob:\n",
        "                num = random.randint(0, 9)\n",
        "            image = random.choice(self.data[color][self.mode][num])\n",
        "            images.append(image)\n",
        "            self.observed_seq.append(num)\n",
        "\n",
        "\n",
        "        return images\n",
        "\n",
        "    def _check_correct_action(self):\n",
        "        correct_number = self.correct_seq[self.current_index]\n",
        "        observed_number = self.observed_seq[self.current_index]\n",
        "        return int(correct_number == observed_number)\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        fig, axs = plt.subplots(1, self.seq_length, figsize=(15, 5))\n",
        "        for i, image in enumerate(self.log['sequence']):\n",
        "            axs[i].imshow(image.permute(1, 2, 0).numpy())\n",
        "            axs[i].axis('off')\n",
        "            if i < len(self.log['actions']):\n",
        "                action = 'InSeq' if self.log['actions'][i] == 1 else 'OutSeq'\n",
        "                axs[i].set_title(f\"Action: {action}\\nReward: {self.log['rewards'][i]}\")\n",
        "\n",
        "        plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "78T1WmAk6Uj0",
        "outputId": "65f3dc54-221c-4dfc-f572-becb03f8f5ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Action: 1, Reward: 0.5, Done: False\n",
            "Action: 0, Reward: 1.0, Done: False\n",
            "Action: 1, Reward: 1.5, Done: True\n",
            "Total Reward: 3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Example\n",
        "env = SequenceEnvironment(CMNIST)\n",
        "total_reward = 0\n",
        "\n",
        "done = False\n",
        "while not done:\n",
        "    action = env.action_space.sample()  # Random action for testing\n",
        "    obs, reward, done, _ = env.step(action)\n",
        "    total_reward += reward\n",
        "    print(f\"Action: {action}, Reward: {reward}, Done: {done}\")\n",
        "\n",
        "print(f\"Total Reward: {total_reward}\")\n",
        "env.render()  # Visualize the episode"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kc8cmNPIGbXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pretext"
      ],
      "metadata": {
        "id": "biNDSIkgoNsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.fc_layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 5 * 5, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64)\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        out1 = self.conv_layers(x1)\n",
        "        out2 = self.conv_layers(x2)\n",
        "        out1 = self.fc_layers(out1.view(out1.size(0), -1))\n",
        "        out2 = self.fc_layers(out2.view(out2.size(0), -1))\n",
        "        return out1, out2\n",
        "\n",
        "    def extract_features(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = self.fc_layers(x.view(x.size(0), -1))\n",
        "        return x\n",
        "\n",
        "    def extract_conv_layers(self):\n",
        "        return self.conv_layers\n"
      ],
      "metadata": {
        "id": "p5JAU5n7oPi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color_emb = SiameseNetwork()\n",
        "color_emb.load_state_dict(torch.load(\"contrastive_model_color\"))\n",
        "color_emb.eval()\n",
        "digit_emb = SiameseNetwork()\n",
        "digit_emb.load_state_dict(torch.load(\"contrastive_model_digit\"))\n",
        "digit_emb.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QS3jc5FZoU3t",
        "outputId": "e35d189a-cfd8-436e-9f33-941b1f9e7d33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-03473d92c61b>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  color_emb.load_state_dict(torch.load(\"contrastive_model_color\"))\n",
            "<ipython-input-13-03473d92c61b>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  digit_emb.load_state_dict(torch.load(\"contrastive_model_digit\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SiameseNetwork(\n",
              "  (conv_layers): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc_layers): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=1600, out_features=128, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=128, out_features=64, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lYco7ga1X_rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HAMI"
      ],
      "metadata": {
        "id": "8I1imysmYAEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define MemoryEntry as a namedtuple\n",
        "MemoryEntry = namedtuple('MemoryEntry', ['context_event_indices', 'action', 'episode_reward'])\n",
        "\n",
        "class IndexTable:\n",
        "    \"\"\"Table to manage context and event indices based on feature vector similarity.\"\"\"\n",
        "    def __init__(self, similarity_threshold=0.9):\n",
        "        self.table = {}\n",
        "        self.index_counter = np.uint8(1)  # Start from 1, 0 is reserved for null states\n",
        "        self.similarity_threshold = similarity_threshold\n",
        "\n",
        "    def _similarity(self, vec1, vec2):\n",
        "        \"\"\"Compute cosine similarity between two vectors.\"\"\"\n",
        "        return F.cosine_similarity(vec1, vec2, dim=0)\n",
        "\n",
        "    def get_or_create_index(self, vector, enforce_threshold=True):\n",
        "        \"\"\"Return index for the most similar vector above threshold or assign a new one if none exist.\"\"\"\n",
        "        best_similarity = -1.0\n",
        "        best_index = None\n",
        "\n",
        "        for stored_vector, idx in self.table.items():\n",
        "            similarity = self._similarity(vector, stored_vector).item()\n",
        "\n",
        "            # Update if similarity is above threshold and higher than previous best\n",
        "            if similarity >= (self.similarity_threshold if enforce_threshold else 0) and similarity > best_similarity:\n",
        "                best_similarity = similarity\n",
        "                best_index = idx\n",
        "\n",
        "        # Use the best match if found, otherwise assign a new index\n",
        "        if best_index is not None:\n",
        "            return best_index\n",
        "\n",
        "        # Assign a new index if no suitable match was found\n",
        "        self.table[vector] = self.index_counter\n",
        "        new_index = self.index_counter\n",
        "        self.index_counter = np.uint8(self.index_counter + 1)  # Increment and ensure it stays as uint8\n",
        "        return new_index\n",
        "\n",
        "\n",
        "class Hippocampus:\n",
        "    def __init__(self, color_emb, digit_emb, capacity=3000, window_size=3, knn=1, context_thr=0.9, event_thr=0.9):\n",
        "        self.color_emb = color_emb.eval()\n",
        "        self.digit_emb = digit_emb.eval()\n",
        "        self.memory = deque(maxlen=capacity)\n",
        "        self.window_size = window_size\n",
        "        self.knn = knn\n",
        "        self.context_table = IndexTable(similarity_threshold=context_thr)\n",
        "        self.event_table = IndexTable(similarity_threshold=event_thr)\n",
        "        self.count_similar = 0\n",
        "        self.count_replace = 0\n",
        "        self.total_steps = 0\n",
        "\n",
        "    def extract_indices(self, sequence, enforce_threshold=True):\n",
        "        \"\"\"Extract indices from feature vectors of contexts and events in a sequence.\"\"\"\n",
        "        with torch.no_grad():\n",
        "            colors = self.color_emb.extract_features(torch.stack(sequence, dim=0))\n",
        "            digits = self.digit_emb.extract_features(torch.stack(sequence, dim=0))\n",
        "\n",
        "        colors = colors.detach()  # Detach the tensor from the computation graph\n",
        "        digits = digits.detach()  # Detach the tensor from the computation graph\n",
        "\n",
        "        context_indices = [self.context_table.get_or_create_index(c, enforce_threshold) for c in colors]\n",
        "        event_indices = [self.event_table.get_or_create_index(d, enforce_threshold) for d in digits]\n",
        "\n",
        "        return context_indices, event_indices\n",
        "\n",
        "\n",
        "\n",
        "    def store_memory(self, env_log, replace_mask, index_list):\n",
        "        episode_length = len(env_log['actions'])\n",
        "        rewards = env_log['rewards']\n",
        "        sequence = env_log['sequence']\n",
        "\n",
        "        context_indices, event_indices = self.extract_indices(sequence, enforce_threshold=True)\n",
        "        episode_rewards = [sum(rewards[i:]) for i in range(episode_length)]\n",
        "\n",
        "        for i in range(episode_length):\n",
        "            context_event_window = self.create_windows(i, context_indices, event_indices)\n",
        "\n",
        "            memory_entry = MemoryEntry(\n",
        "                context_event_indices=context_event_window,\n",
        "                action=env_log['actions'][i],\n",
        "                episode_reward=episode_rewards[i]\n",
        "            )\n",
        "            if replace_mask[i]:\n",
        "                self.count_similar += 1\n",
        "                if self.memory[index_list[i]].episode_reward < episode_rewards[i]:\n",
        "                    self.memory[index_list[i]] = memory_entry  # Replace memory entry with new one if higher reward\n",
        "                    self.count_replace += 1\n",
        "            else:\n",
        "                self.memory.append(memory_entry)\n",
        "\n",
        "    def create_windows(self, i, context_indices, event_indices):\n",
        "        \"\"\"Create context-event windows with previous, current, and next indices.\"\"\"\n",
        "        if i == 0:\n",
        "            context_event_window = [(np.uint8(0), np.uint8(0)), (np.uint8(0), np.uint8(0)), (context_indices[i], event_indices[i])]\n",
        "        elif i == 1:\n",
        "            context_event_window = [(np.uint8(0), np.uint8(0)), (context_indices[i - 1], event_indices[i - 1]),\n",
        "                                    (context_indices[i], event_indices[i])]\n",
        "        else:\n",
        "            context_event_window = [(context_indices[i - 2], event_indices[i - 2]),\n",
        "                                    (context_indices[i - 1], event_indices[i - 1]),\n",
        "                                    (context_indices[i], event_indices[i])]\n",
        "        return context_event_window\n",
        "\n",
        "    def memory_batch(self):\n",
        "        \"\"\"Return a batch of memory entries.\"\"\"\n",
        "        return MemoryEntry(*zip(*self.memory))\n",
        "\n",
        "    def working_memory(self, env, enforce_threshold=True):\n",
        "        \"\"\"Retrieve current working memory indices with padded previous states.\"\"\"\n",
        "        current_index = env.current_index\n",
        "        current_sequence = env.current_sequence\n",
        "        context_indices, event_indices = self.extract_indices(current_sequence[:current_index + 1], enforce_threshold)\n",
        "\n",
        "        wm_context = [np.uint8(0)] * (self.window_size - 1 - current_index) + context_indices\n",
        "        wm_event = [np.uint8(0)] * (self.window_size - 1 - current_index) + event_indices\n",
        "        working_memory = [(wm_context[i], wm_event[i]) for i in range(self.window_size)]\n",
        "        return working_memory\n",
        "\n",
        "    def _similarity_score(self, wm_entry, mem_entry):\n",
        "        \"\"\"Compute similarity between working memory and episodic memory entry.\"\"\"\n",
        "        similarity = sum(1 if wm_entry[i] == mem_entry[i] else 0 for i in range(self.window_size))\n",
        "        return similarity / self.window_size  # Similarity as fraction of matching pairs\n",
        "\n",
        "    def memory_lookup(self, working_memory):\n",
        "        \"\"\"Find the most similar memory entry based on context-event indices.\"\"\"\n",
        "        similarities = [self._similarity_score(working_memory, mem_entry.context_event_indices)\n",
        "                        for mem_entry in self.memory]\n",
        "        return torch.tensor(similarities)\n",
        "\n",
        "    def Avg_KNN(self, working_memory):\n",
        "        \"\"\"Retrieve the best action based on k-nearest neighbors.\"\"\"\n",
        "        if len(self.memory) == 0:\n",
        "            return {0: -1, 1: -1}, {0: None, 1: None}, {0: 0, 1: 0}\n",
        "\n",
        "        similarity_scores = self.memory_lookup(working_memory)\n",
        "        memory_batch = self.memory_batch()\n",
        "        actions = torch.tensor(memory_batch.action)\n",
        "        rewards = torch.tensor(memory_batch.episode_reward)\n",
        "\n",
        "        action_rewards = {}\n",
        "        memory_index = {}\n",
        "        action_similarity = {}\n",
        "\n",
        "        for action in range(2):\n",
        "            action_indices = torch.where(actions == action)[0]\n",
        "            if len(action_indices) > 0:\n",
        "                action_similarities = similarity_scores[action_indices]\n",
        "                top_k_values, top_k_indices = torch.topk(action_similarities, self.knn)\n",
        "                nearest_neighbor = action_indices[top_k_indices[0]]\n",
        "                avg_reward = rewards[nearest_neighbor].float().item()\n",
        "\n",
        "                action_rewards[action] = avg_reward\n",
        "                memory_index[action] = nearest_neighbor.item()\n",
        "                action_similarity[action] = top_k_values[0].item()\n",
        "            else:\n",
        "                action_rewards[action] = -1.0\n",
        "                memory_index[action] = None\n",
        "                action_similarity[action] = 0.0\n",
        "\n",
        "        return action_rewards, memory_index, action_similarity\n",
        "\n",
        "\n",
        "    def train(self, env, num_episodes, epsilon_start=1.0, epsilon_end=0.01, epsilon_decay=0.995):\n",
        "        epsilon = epsilon_start\n",
        "        episode_rewards = []\n",
        "\n",
        "        for episode in tqdm(range(num_episodes)):\n",
        "            state = env.reset()\n",
        "            done = False\n",
        "            episode_reward = 0\n",
        "            replace_mask = []\n",
        "            index_list = []\n",
        "\n",
        "            while not done:\n",
        "                working_memory = self.working_memory(env)\n",
        "                action_rewards, memory_index, action_similarity = self.Avg_KNN(working_memory)\n",
        "\n",
        "                if random.random() < epsilon:\n",
        "                    action = env.action_space.sample()\n",
        "                else:\n",
        "                    action = max(action_rewards, key=action_rewards.get)\n",
        "\n",
        "\n",
        "                if action_similarity[action] < 1.0:  # Only replace if not an exact match\n",
        "                    replace_mask.append(False)\n",
        "                else:\n",
        "                    replace_mask.append(True)\n",
        "                index_list.append(memory_index[action])\n",
        "\n",
        "                next_state, reward, done, _ = env.step(action)\n",
        "                episode_reward += reward\n",
        "\n",
        "                self.total_steps += 1\n",
        "\n",
        "\n",
        "            self.store_memory(env.log, replace_mask, index_list)\n",
        "            epsilon = max(epsilon_end, epsilon * epsilon_decay)\n",
        "            episode_rewards.append(episode_reward)\n",
        "\n",
        "            if (episode + 1) % 100 == 0:\n",
        "                print(f\"Episode {episode + 1}, Avg Reward: {sum(episode_rewards[-100:]) / 100:.2f}, Epsilon: {epsilon:.2f}\")\n",
        "\n",
        "        return episode_rewards\n",
        "\n",
        "    def test(self, env, num_episodes):\n",
        "        total_rewards = []\n",
        "        correct_actions = 0\n",
        "        total_actions = 0\n",
        "\n",
        "        for episode in tqdm(range(num_episodes)):\n",
        "            state = env.reset()\n",
        "            done = False\n",
        "            episode_reward = 0\n",
        "\n",
        "            while not done:\n",
        "                working_memory = self.working_memory(env, enforce_threshold=False)\n",
        "                action_rewards, _, _ = self.Avg_KNN(working_memory)\n",
        "                action = max(action_rewards, key=action_rewards.get)\n",
        "\n",
        "                next_state, reward, done, info = env.step(action)\n",
        "                episode_reward += reward\n",
        "\n",
        "                if action == env.correct_action:\n",
        "                    correct_actions += 1\n",
        "                total_actions += 1\n",
        "\n",
        "            total_rewards.append(episode_reward)\n",
        "\n",
        "        avg_reward = torch.tensor(total_rewards).mean().item()\n",
        "        avg_accuracy = correct_actions / total_actions\n",
        "\n",
        "        return avg_reward, avg_accuracy, total_rewards, correct_actions, total_actions\n"
      ],
      "metadata": {
        "id": "lQPZjTWeGrpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v3c5lw_5HDkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample Experiment"
      ],
      "metadata": {
        "id": "xtQSt094P2aF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hip = Hippocampus(color_emb, digit_emb, capacity=1000, context_thr=0.9, event_thr=0.7)\n",
        "train_env = SequenceEnvironment(CMNIST, mode='train')\n",
        "\n",
        "start_time = time.time()\n",
        "train_rewards = hip.train(train_env, num_episodes=1000,epsilon_decay=0.999)\n",
        "end_time = time.time()\n",
        "print(f\"Total Training time is {end_time-start_time: .4f} seconds\")"
      ],
      "metadata": {
        "id": "2TGoUjbf173T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3650c6f7-a789-467f-fe2f-2ea3bf10a306"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 107/1000 [00:01<00:16, 54.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 100, Avg Reward: 0.15, Epsilon: 0.90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 209/1000 [00:04<00:15, 52.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 200, Avg Reward: -0.10, Epsilon: 0.82\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███▏      | 314/1000 [00:06<00:08, 82.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 300, Avg Reward: 0.23, Epsilon: 0.74\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 406/1000 [00:07<00:08, 68.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 400, Avg Reward: 0.17, Epsilon: 0.67\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 512/1000 [00:08<00:07, 61.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 500, Avg Reward: 0.35, Epsilon: 0.61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 609/1000 [00:10<00:06, 59.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 600, Avg Reward: 0.69, Epsilon: 0.55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 706/1000 [00:12<00:04, 61.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 700, Avg Reward: 0.55, Epsilon: 0.50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 801/1000 [00:15<00:12, 16.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 800, Avg Reward: 1.00, Epsilon: 0.45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 903/1000 [00:19<00:02, 32.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 900, Avg Reward: 0.99, Epsilon: 0.41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:22<00:00, 44.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1000, Avg Reward: 1.38, Epsilon: 0.37\n",
            "Total Training time is  22.4482 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of Context Symbols: {len(hip.context_table.table)}\")\n",
        "print(f\"Number of Event Symbols: {len(hip.event_table.table)}\")\n",
        "print('--------------------------------------------------')\n",
        "print(f\"Similar Episodic Memories ran into: {hip.count_similar}\")\n",
        "print(f\"Number of Episodic Memory Entries Replaced: {hip.count_replace}\")\n",
        "print('--------------------------------------------------')\n",
        "print(f\"Total Steps during Training: {hip.total_steps}\")\n",
        "print(f\"Occupied Memory: {len(hip.memory)}\")"
      ],
      "metadata": {
        "id": "uGt73yTWB_fB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3091feb-78a4-4fcc-f3fc-234518a53651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Context Symbols: 4\n",
            "Number of Event Symbols: 11\n",
            "--------------------------------------------------\n",
            "Similar Episodic Memories ran into: 1590\n",
            "Number of Episodic Memory Entries Replaced: 36\n",
            "--------------------------------------------------\n",
            "Total Steps during Training: 2151\n",
            "Occupied Memory: 561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "test_env = SequenceEnvironment(CMNIST, mode='test')\n",
        "\n",
        "start_time = time.time()\n",
        "avg_reward, avg_accuracy, total_rewards, correct_actions, total_actions = hip.test(test_env, num_episodes=1000)\n",
        "end_time = time.time()\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "print(f\"Average Reward: {avg_reward:.4f}\")\n",
        "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
        "print('--------------------------------------------------')\n",
        "print(f\"correct_actions: {correct_actions}\")\n",
        "print(f\"total_actions: {total_actions}\")\n",
        "\n",
        "print('--------------------------------------------------')\n",
        "print(f\"Total inference time is {end_time-start_time: .4f} seconds\")\n",
        "print('--------------------------------------------------')\n",
        "pd.Series(total_rewards).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "XwsiR9KhQZiI",
        "outputId": "4a74802b-0643-4bd0-c363-1c976a0d09e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:18<00:00, 55.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Average Reward: 2.3295\n",
            "Average Accuracy: 0.9228\n",
            "--------------------------------------------------\n",
            "correct_actions: 2664\n",
            "total_actions: 2887\n",
            "--------------------------------------------------\n",
            "Total inference time is  18.0336 seconds\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 3.0    777\n",
              "-0.5    113\n",
              " 0.5    110\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>-0.5</th>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.5</th>\n",
              "      <td>110</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YDU0RC3_RAnF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}